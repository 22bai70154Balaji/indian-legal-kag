# """

# Article 21 Privacy Rights Specialized Analyzer - Complete Updated Version

# Enhanced with comprehensive privacy analysis framework

# """

# import logging
# import re
# from typing import Dict, List, Any, Optional, Tuple
# from datetime import datetime
# from core.knowledge_graph.neo4j_manager import ConstitutionalKnowledgeGraph

# logger = logging.getLogger(__name__)

# class Article21PrivacyAnalyzer:
#     """Specialized analyzer for Article 21 privacy rights implications"""

#     def __init__(self):
#         try:
#             self.kg = ConstitutionalKnowledgeGraph()
#         except Exception as e:
#             logger.warning(f"Knowledge graph not available: {str(e)}")
#             self.kg = None
            
#         self.privacy_keywords = self._initialize_privacy_keywords()
#         self.privacy_categories = self._initialize_privacy_categories()
#         self.puttaswamy_principles = self._initialize_puttaswamy_principles()

#     def _initialize_privacy_keywords(self) -> Dict[str, List[str]]:
#         """Initialize privacy-related keywords for detection"""
#         return {
#             "personal_data": [
#                 "personal information", "personal data", "individual data",
#                 "private information", "confidential data", "sensitive data",
#                 "biometric data", "genetic data", "health data", "financial data",
#                 "behavioral data", "location data", "communication data"
#             ],
#             "data_processing": [
#                 "data collection", "data processing", "data storage", "data sharing",
#                 "data transfer", "data analysis", "data mining", "profiling",
#                 "automated decision making", "algorithmic processing",
#                 "data aggregation", "data linking", "data matching"
#             ],
#             "consent_related": [
#                 "consent", "authorization", "permission", "approval",
#                 "opt-in", "opt-out", "withdraw consent", "explicit consent",
#                 "informed consent", "free consent", "specific consent",
#                 "granular consent", "consent management"
#             ],
#             "surveillance": [
#                 "surveillance", "monitoring", "tracking", "observation",
#                 "recording", "interception", "eavesdropping", "wiretapping",
#                 "location tracking", "behavioral monitoring", "cctv",
#                 "facial recognition", "biometric surveillance"
#             ],
#             "data_rights": [
#                 "right to access", "right to rectification", "right to erasure",
#                 "right to portability", "right to be forgotten", "data subject rights",
#                 "right to object", "right to restrict processing",
#                 "right to information", "right to correction"
#             ]
#         }

#     def _initialize_privacy_categories(self) -> Dict[str, Dict[str, Any]]:
#         """Initialize privacy categories as per Puttaswamy judgment"""
#         return {
#             "informational_privacy": {
#                 "description": "Control over personal information and its disclosure",
#                 "constitutional_basis": "Article 21",
#                 "scope": ["personal data", "information disclosure", "data sharing", "data processing"],
#                 "dpdpa_sections": ["section_3", "section_5", "section_8"],
#                 "puttaswamy_reference": "Privacy of information and the right to control dissemination of personal information",
#                 "keywords": ["personal data", "information", "disclosure", "sharing", "processing"]
#             },
#             "bodily_privacy": {
#                 "description": "Protection of physical self from unauthorized intrusion",
#                 "constitutional_basis": "Article 21",
#                 "scope": ["physical examination", "medical procedures", "biometric collection", "body searches"],
#                 "dpdpa_sections": ["section_5"],
#                 "puttaswamy_reference": "Bodily integrity and protection from physical intrusion",
#                 "keywords": ["biometric", "physical", "medical", "body", "examination"]
#             },
#             "communications_privacy": {
#                 "description": "Privacy of communications and correspondence",
#                 "constitutional_basis": "Article 21",
#                 "scope": ["phone calls", "emails", "messages", "correspondence", "communications"],
#                 "dpdpa_sections": ["section_5", "section_8"],
#                 "puttaswamy_reference": "Privacy of communication and correspondence",
#                 "keywords": ["communication", "correspondence", "messages", "calls", "emails"]
#             },
#             "territorial_privacy": {
#                 "description": "Protection of private spaces",
#                 "constitutional_basis": "Article 21",
#                 "scope": ["home", "private property", "personal space", "premises"],
#                 "dpdpa_sections": [],
#                 "puttaswamy_reference": "Spatial privacy and sanctity of private spaces",
#                 "keywords": ["home", "premises", "property", "space", "territory"]
#             }
#         }

#     def _initialize_puttaswamy_principles(self) -> List[Dict[str, Any]]:
#         """Initialize key principles from Puttaswamy judgment"""
#         return [
#             {
#                 "principle": "Privacy as Fundamental Right",
#                 "description": "Privacy is protected as an intrinsic part of the right to life and personal liberty under Article 21",
#                 "legal_test": "Three-fold test: legitimate government aim, necessity, and proportionality",
#                 "implications": ["Data protection laws must meet constitutional standards", "Privacy cannot be compromised arbitrarily"],
#                 "keywords": ["fundamental right", "article 21", "constitutional protection"]
#             },
#             {
#                 "principle": "Informational Self-Determination",
#                 "description": "Individuals must have control over their personal information",
#                 "legal_test": "Consent-based processing with legitimate purpose",
#                 "implications": ["Meaningful consent required", "Purpose limitation necessary"],
#                 "keywords": ["control", "consent", "self-determination", "autonomy"]
#             },
#             {
#                 "principle": "Data Minimization",
#                 "description": "Collection and processing must be limited to what is necessary",
#                 "legal_test": "Proportionality test",
#                 "implications": ["Excessive data collection violates privacy", "Storage limitation required"],
#                 "keywords": ["minimization", "necessary", "proportional", "limited"]
#             },
#             {
#                 "principle": "Transparency and Accountability",
#                 "description": "Data processing must be transparent and accountable",
#                 "legal_test": "Clear disclosure of processing activities",
#                 "implications": ["Privacy notices required", "Data protection impact assessments necessary"],
#                 "keywords": ["transparency", "accountability", "disclosure", "notice"]
#             }
#         ]

#     def analyze_privacy_implications(self, document_text: str) -> Dict[str, Any]:
#         """Comprehensive privacy analysis under Article 21 framework"""
#         logger.info("ðŸ”’ Starting Article 21 privacy analysis...")

#         try:
#             # Step 1: Extract privacy-related clauses
#             privacy_clauses = self._extract_privacy_clauses(document_text)

#             # Step 2: Categorize privacy implications
#             privacy_categorization = self._categorize_privacy_implications(privacy_clauses, document_text)

#             # Step 3: Apply Puttaswamy principles
#             puttaswamy_analysis = self._apply_puttaswamy_principles(privacy_clauses, document_text)

#             # Step 4: Analyze constitutional compliance
#             constitutional_compliance = self._analyze_constitutional_privacy_compliance(
#                 privacy_clauses, privacy_categorization, puttaswamy_analysis
#             )

#             # Step 5: Generate DPDPA mapping
#             dpdpa_mapping = self._map_to_dpdpa_provisions(privacy_categorization)

#             # Step 6: Calculate privacy risk score
#             privacy_risk_score = self._calculate_privacy_risk_score(
#                 privacy_clauses, constitutional_compliance, dpdpa_mapping
#             )

#             # Step 7: Generate constitutional reasoning pathway
#             constitutional_pathway = self._trace_constitutional_privacy_pathway(privacy_categorization)

#             return {
#                 "privacy_clauses": privacy_clauses,
#                 "privacy_categorization": privacy_categorization,
#                 "puttaswamy_analysis": puttaswamy_analysis,
#                 "constitutional_compliance": constitutional_compliance,
#                 "dpdpa_mapping": dpdpa_mapping,
#                 "privacy_risk_score": privacy_risk_score,
#                 "constitutional_pathway": constitutional_pathway,
#                 "analysis_timestamp": datetime.now().isoformat(),
#                 "article_21_compliance": self._assess_article_21_compliance(constitutional_compliance)
#             }

#         except Exception as e:
#             logger.error(f"âŒ Privacy analysis failed: {str(e)}")
#             return self._generate_privacy_error_response(str(e))

#     def _extract_privacy_clauses(self, document_text: str) -> List[Dict[str, Any]]:
#         """Extract privacy-related clauses from document"""
#         privacy_clauses = []
#         sentences = document_text.split('.')

#         for i, sentence in enumerate(sentences):
#             sentence = sentence.strip()
#             if len(sentence) < 10:  # Skip very short sentences
#                 continue

#             clause_analysis = {
#                 "sentence_id": i,
#                 "text": sentence,
#                 "privacy_keywords": [],
#                 "privacy_categories": [],
#                 "intensity_score": 0.0,
#                 "clause_type": "general"
#             }

#             # Check for privacy keywords
#             for category, keywords in self.privacy_keywords.items():
#                 found_keywords = []
#                 for keyword in keywords:
#                     if keyword.lower() in sentence.lower():
#                         found_keywords.append(keyword)
#                         clause_analysis["intensity_score"] += 0.1

#                 if found_keywords:
#                     clause_analysis["privacy_keywords"].extend(found_keywords)
#                     clause_analysis["privacy_categories"].append(category)

#             # Determine clause type
#             if clause_analysis["privacy_keywords"]:
#                 clause_analysis["clause_type"] = self._determine_clause_type(sentence, clause_analysis["privacy_keywords"])

#             # Only include clauses with privacy relevance
#             if clause_analysis["intensity_score"] > 0:
#                 privacy_clauses.append(clause_analysis)

#         # Sort by intensity score
#         privacy_clauses.sort(key=lambda x: x["intensity_score"], reverse=True)
#         return privacy_clauses[:20]  # Return top 20 most relevant clauses

#     def _determine_clause_type(self, sentence: str, keywords: List[str]) -> str:
#         """Determine the type of privacy clause"""
#         sentence_lower = sentence.lower()
        
#         if any(kw in sentence_lower for kw in ["consent", "authorization", "permission"]):
#             return "consent_clause"
#         elif any(kw in sentence_lower for kw in ["collect", "process", "store"]):
#             return "data_processing_clause"
#         elif any(kw in sentence_lower for kw in ["share", "transfer", "disclose"]):
#             return "data_sharing_clause"
#         elif any(kw in sentence_lower for kw in ["right", "access", "rectify", "delete"]):
#             return "rights_clause"
#         elif any(kw in sentence_lower for kw in ["security", "protect", "safeguard"]):
#             return "security_clause"
#         else:
#             return "general_privacy_clause"

#     def _categorize_privacy_implications(self, privacy_clauses: List[Dict], document_text: str) -> Dict[str, Any]:
#         """Categorize privacy implications according to Puttaswamy framework"""
#         categorization = {
#             "informational_privacy": {"score": 0.0, "clauses": [], "implications": []},
#             "bodily_privacy": {"score": 0.0, "clauses": [], "implications": []},
#             "communications_privacy": {"score": 0.0, "clauses": [], "implications": []},
#             "territorial_privacy": {"score": 0.0, "clauses": [], "implications": []},
#             "overall_privacy_impact": "low"
#         }

#         for clause in privacy_clauses:
#             clause_text = clause["text"].lower()

#             # Check against each privacy category
#             for category_name, category_info in self.privacy_categories.items():
#                 category_score = 0.0
#                 category_implications = []

#                 # Check scope keywords
#                 for scope_item in category_info["scope"]:
#                     if scope_item.lower() in clause_text:
#                         category_score += 0.3
#                         category_implications.append(f"Affects {scope_item}")

#                 # Check category-specific keywords
#                 for keyword in category_info["keywords"]:
#                     if keyword.lower() in clause_text:
#                         category_score += 0.2

#                 # Check privacy keywords relevance
#                 for keyword_category in clause["privacy_categories"]:
#                     if self._is_keyword_category_relevant_to_privacy_category(keyword_category, category_name):
#                         category_score += 0.2
#                         category_implications.append(f"Related to {keyword_category}")

#                 if category_score > 0:
#                     categorization[category_name]["score"] += category_score
#                     categorization[category_name]["clauses"].append({
#                         "clause_id": clause["sentence_id"],
#                         "text": clause["text"],
#                         "relevance_score": category_score
#                     })
#                     categorization[category_name]["implications"].extend(category_implications)

#         # Determine overall privacy impact
#         total_score = sum(cat["score"] for cat in categorization.values() if isinstance(cat, dict) and "score" in cat)
#         if total_score > 3.0:
#             categorization["overall_privacy_impact"] = "critical"
#         elif total_score > 2.0:
#             categorization["overall_privacy_impact"] = "high"
#         elif total_score > 1.0:
#             categorization["overall_privacy_impact"] = "medium"
#         else:
#             categorization["overall_privacy_impact"] = "low"

#         return categorization

#     def _is_keyword_category_relevant_to_privacy_category(self, keyword_category: str, privacy_category: str) -> bool:
#         """Check if keyword category is relevant to privacy category"""
#         relevance_mapping = {
#             "informational_privacy": ["personal_data", "data_processing", "data_rights"],
#             "bodily_privacy": ["personal_data", "surveillance"],
#             "communications_privacy": ["personal_data", "data_processing", "surveillance"],
#             "territorial_privacy": ["surveillance"]
#         }
#         return keyword_category in relevance_mapping.get(privacy_category, [])

#     def _apply_puttaswamy_principles(self, privacy_clauses: List[Dict], document_text: str) -> Dict[str, Any]:
#         """Apply Puttaswamy judgment principles to document analysis"""
#         principle_analysis = {}

#         for principle in self.puttaswamy_principles:
#             principle_name = principle["principle"]
#             analysis = {
#                 "principle": principle_name,
#                 "description": principle["description"],
#                 "compliance_status": "unknown",
#                 "compliance_score": 0.0,
#                 "evidence": [],
#                 "violations": [],
#                 "recommendations": []
#             }

#             # Analyze compliance for each principle
#             if principle_name == "Privacy as Fundamental Right":
#                 analysis = self._analyze_fundamental_right_compliance(analysis, privacy_clauses, document_text)
#             elif principle_name == "Informational Self-Determination":
#                 analysis = self._analyze_self_determination_compliance(analysis, privacy_clauses, document_text)
#             elif principle_name == "Data Minimization":
#                 analysis = self._analyze_minimization_compliance(analysis, privacy_clauses, document_text)
#             elif principle_name == "Transparency and Accountability":
#                 analysis = self._analyze_transparency_compliance(analysis, privacy_clauses, document_text)

#             principle_analysis[principle_name] = analysis

#         return principle_analysis

#     def _analyze_fundamental_right_compliance(self, analysis: Dict, privacy_clauses: List[Dict], document_text: str) -> Dict:
#         """Analyze compliance with privacy as fundamental right"""
#         score = 0.5  # Base score
#         evidence = []
#         violations = []
#         recommendations = []

#         # Check for constitutional references
#         if "article 21" in document_text.lower() or "fundamental right" in document_text.lower():
#             score += 0.3
#             evidence.append("Document references constitutional privacy rights")
#         else:
#             violations.append("No reference to constitutional basis of privacy rights")
#             recommendations.append("Include reference to Article 21 and constitutional privacy framework")

#         # Check for privacy protection measures
#         protection_terms = ["protect", "safeguard", "secure", "privacy policy", "data protection"]
#         protection_count = sum(1 for term in protection_terms if term in document_text.lower())
        
#         if protection_count >= 3:
#             score += 0.2
#             evidence.append("Multiple privacy protection measures mentioned")
#         elif protection_count >= 1:
#             score += 0.1
#         else:
#             violations.append("Insufficient privacy protection measures")
#             recommendations.append("Implement comprehensive privacy protection measures")

#         analysis.update({
#             "compliance_score": min(1.0, score),
#             "compliance_status": "compliant" if score >= 0.7 else "non_compliant" if score < 0.4 else "partially_compliant",
#             "evidence": evidence,
#             "violations": violations,
#             "recommendations": recommendations
#         })

#         return analysis

#     def _analyze_self_determination_compliance(self, analysis: Dict, privacy_clauses: List[Dict], document_text: str) -> Dict:
#         """Analyze compliance with informational self-determination"""
#         score = 0.4  # Base score
#         evidence = []
#         violations = []
#         recommendations = []

#         # Check for consent mechanisms
#         consent_terms = ["consent", "choice", "control", "opt-in", "opt-out"]
#         consent_mentions = sum(1 for term in consent_terms if term in document_text.lower())
        
#         if consent_mentions >= 3:
#             score += 0.4
#             evidence.append("Multiple consent and control mechanisms mentioned")
#         elif consent_mentions >= 1:
#             score += 0.2
#             evidence.append("Some consent mechanisms present")
#         else:
#             violations.append("No clear consent mechanisms identified")
#             recommendations.append("Implement clear consent collection and management procedures")

#         # Check for user control features
#         control_terms = ["withdraw", "modify", "update", "delete", "access"]
#         control_count = sum(1 for term in control_terms if term in document_text.lower())
        
#         if control_count >= 2:
#             score += 0.2
#             evidence.append("User control features mentioned")
#         else:
#             violations.append("Limited user control over personal information")
#             recommendations.append("Provide comprehensive user control mechanisms")

#         analysis.update({
#             "compliance_score": min(1.0, score),
#             "compliance_status": "compliant" if score >= 0.7 else "non_compliant" if score < 0.4 else "partially_compliant",
#             "evidence": evidence,
#             "violations": violations,
#             "recommendations": recommendations
#         })

#         return analysis

#     def _analyze_minimization_compliance(self, analysis: Dict, privacy_clauses: List[Dict], document_text: str) -> Dict:
#         """Analyze compliance with data minimization principle"""
#         score = 0.3  # Base score
#         evidence = []
#         violations = []
#         recommendations = []

#         # Check for minimization language
#         minimization_terms = ["necessary", "required", "essential", "minimum", "limited", "specific purpose"]
#         minimization_count = sum(1 for term in minimization_terms if term in document_text.lower())
        
#         if minimization_count >= 3:
#             score += 0.4
#             evidence.append("Data minimization language present")
#         elif minimization_count >= 1:
#             score += 0.2
#         else:
#             violations.append("No data minimization principles mentioned")
#             recommendations.append("Implement data minimization practices")

#         # Check for retention limitations
#         retention_terms = ["retention", "storage period", "delete after", "expire"]
#         if any(term in document_text.lower() for term in retention_terms):
#             score += 0.3
#             evidence.append("Data retention limitations mentioned")
#         else:
#             violations.append("No data retention limitations specified")
#             recommendations.append("Define clear data retention and deletion policies")

#         analysis.update({
#             "compliance_score": min(1.0, score),
#             "compliance_status": "compliant" if score >= 0.7 else "non_compliant" if score < 0.4 else "partially_compliant",
#             "evidence": evidence,
#             "violations": violations,
#             "recommendations": recommendations
#         })

#         return analysis

#     def _analyze_transparency_compliance(self, analysis: Dict, privacy_clauses: List[Dict], document_text: str) -> Dict:
#         """Analyze compliance with transparency and accountability"""
#         score = 0.4  # Base score
#         evidence = []
#         violations = []
#         recommendations = []

#         # Check for transparency measures
#         transparency_terms = ["notice", "inform", "disclose", "transparency", "privacy policy"]
#         transparency_count = sum(1 for term in transparency_terms if term in document_text.lower())
        
#         if transparency_count >= 3:
#             score += 0.3
#             evidence.append("Multiple transparency measures mentioned")
#         elif transparency_count >= 1:
#             score += 0.2
#         else:
#             violations.append("Insufficient transparency measures")
#             recommendations.append("Implement comprehensive privacy notices and transparency measures")

#         # Check for accountability measures
#         accountability_terms = ["responsible", "accountable", "audit", "review", "compliance"]
#         accountability_count = sum(1 for term in accountability_terms if term in document_text.lower())
        
#         if accountability_count >= 2:
#             score += 0.3
#             evidence.append("Accountability measures present")
#         else:
#             violations.append("Limited accountability mechanisms")
#             recommendations.append("Establish clear accountability and audit mechanisms")

#         analysis.update({
#             "compliance_score": min(1.0, score),
#             "compliance_status": "compliant" if score >= 0.7 else "non_compliant" if score < 0.4 else "partially_compliant",
#             "evidence": evidence,
#             "violations": violations,
#             "recommendations": recommendations
#         })

#         return analysis

#     def _analyze_constitutional_privacy_compliance(self, privacy_clauses: List[Dict], categorization: Dict, puttaswamy_analysis: Dict) -> Dict[str, Any]:
#         """Analyze constitutional compliance of privacy provisions"""
#         compliance_analysis = {
#             "article_21_compliance": "unknown",
#             "constitutional_test_results": {},
#             "compliance_score": 0.0,
#             "critical_issues": [],
#             "recommendations": [],
#             "legal_precedents": []
#         }

#         # Apply three-fold constitutional test from Puttaswamy
#         test_results = self._apply_constitutional_test(privacy_clauses, categorization)
#         compliance_analysis["constitutional_test_results"] = test_results

#         # Calculate compliance score based on test results
#         test_scores = [result.get("score", 0) for result in test_results.values()]
#         compliance_analysis["compliance_score"] = sum(test_scores) / len(test_scores) if test_scores else 0.0

#         # Determine overall compliance status
#         if compliance_analysis["compliance_score"] >= 0.8:
#             compliance_analysis["article_21_compliance"] = "compliant"
#         elif compliance_analysis["compliance_score"] >= 0.6:
#             compliance_analysis["article_21_compliance"] = "partially_compliant"
#         else:
#             compliance_analysis["article_21_compliance"] = "non_compliant"

#         # Identify critical issues
#         compliance_analysis["critical_issues"] = self._identify_privacy_critical_issues(
#             privacy_clauses, test_results, puttaswamy_analysis
#         )

#         # Generate recommendations
#         compliance_analysis["recommendations"] = self._generate_privacy_recommendations(
#             compliance_analysis["critical_issues"], test_results
#         )

#         # Add relevant legal precedents
#         compliance_analysis["legal_precedents"] = self._get_relevant_privacy_precedents()

#         return compliance_analysis

#     def _apply_constitutional_test(self, privacy_clauses: List[Dict], categorization: Dict) -> Dict[str, Any]:
#         """Apply three-fold constitutional test: legitimate aim, necessity, proportionality"""
#         return {
#             "legitimate_government_aim": {
#                 "test": "Does the privacy limitation serve a legitimate government purpose?",
#                 "score": self._assess_legitimate_aim(privacy_clauses),
#                 "reasoning": self._explain_legitimate_aim_assessment(privacy_clauses)
#             },
#             "necessity": {
#                 "test": "Is the privacy limitation necessary to achieve the legitimate aim?",
#                 "score": self._assess_necessity(privacy_clauses, categorization),
#                 "reasoning": self._explain_necessity_assessment(privacy_clauses)
#             },
#             "proportionality": {
#                 "test": "Is the privacy limitation proportionate to the aim sought to be achieved?",
#                 "score": self._assess_proportionality(privacy_clauses, categorization),
#                 "reasoning": self._explain_proportionality_assessment(privacy_clauses)
#             }
#         }

#     def _assess_legitimate_aim(self, privacy_clauses: List[Dict]) -> float:
#         """Assess whether privacy limitations serve legitimate purpose"""
#         legitimate_purposes = [
#             "security", "safety", "law enforcement", "public health", 
#             "regulatory compliance", "fraud prevention", "service provision"
#         ]
        
#         purpose_mentions = 0
#         total_clauses = max(len(privacy_clauses), 1)
        
#         for clause in privacy_clauses:
#             clause_text = clause["text"].lower()
#             for purpose in legitimate_purposes:
#                 if purpose in clause_text:
#                     purpose_mentions += 1
#                     break
        
#         return min(1.0, (purpose_mentions / total_clauses) + 0.3)

#     def _assess_necessity(self, privacy_clauses: List[Dict], categorization: Dict) -> float:
#         """Assess necessity of privacy limitations"""
#         necessity_indicators = ["necessary", "required", "essential", "mandatory", "needed"]
        
#         necessity_mentions = 0
#         for clause in privacy_clauses:
#             clause_text = clause["text"].lower()
#             if any(indicator in clause_text for indicator in necessity_indicators):
#                 necessity_mentions += 1
        
#         total_clauses = max(len(privacy_clauses), 1)
#         base_score = necessity_mentions / total_clauses
        
#         # Adjust based on privacy impact
#         privacy_impact = categorization.get("overall_privacy_impact", "low")
#         impact_adjustment = {
#             "critical": -0.2,
#             "high": -0.1,
#             "medium": 0.0,
#             "low": 0.1
#         }.get(privacy_impact, 0.0)
        
#         return min(1.0, max(0.0, base_score + 0.4 + impact_adjustment))

#     def _assess_proportionality(self, privacy_clauses: List[Dict], categorization: Dict) -> float:
#         """Assess proportionality of privacy limitations"""
#         proportionality_indicators = ["proportionate", "reasonable", "appropriate", "balanced"]
        
#         proportionality_mentions = 0
#         for clause in privacy_clauses:
#             clause_text = clause["text"].lower()
#             if any(indicator in clause_text for indicator in proportionality_indicators):
#                 proportionality_mentions += 1
        
#         # Base score from mentions
#         total_clauses = max(len(privacy_clauses), 1)
#         base_score = (proportionality_mentions / total_clauses) + 0.5
        
#         # Adjust based on privacy categories affected
#         categories_affected = sum(1 for cat, data in categorization.items() 
#                                 if isinstance(data, dict) and data.get("score", 0) > 0)
        
#         if categories_affected > 3:
#             base_score -= 0.2  # More categories affected = less proportionate
#         elif categories_affected <= 1:
#             base_score += 0.2  # Fewer categories = more proportionate
            
#         return min(1.0, max(0.0, base_score))

#     def _explain_legitimate_aim_assessment(self, privacy_clauses: List[Dict]) -> str:
#         """Explain legitimate aim assessment"""
#         return "Assessment based on identification of legitimate purposes for privacy-related provisions in the document."

#     def _explain_necessity_assessment(self, privacy_clauses: List[Dict]) -> str:
#         """Explain necessity assessment"""
#         return "Assessment based on explicit necessity language and justification for privacy limitations."

#     def _explain_proportionality_assessment(self, privacy_clauses: List[Dict]) -> str:
#         """Explain proportionality assessment"""
#         return "Assessment based on balance between privacy limitations and legitimate aims, considering scope of impact."

#     def _map_to_dpdpa_provisions(self, categorization: Dict) -> Dict[str, Any]:
#         """Map privacy categories to DPDPA provisions"""
#         dpdpa_mapping = {
#             "relevant_sections": [],
#             "compliance_requirements": [],
#             "implementation_notes": []
#         }

#         for category, data in categorization.items():
#             if isinstance(data, dict) and data.get("score", 0) > 0:
#                 if category in self.privacy_categories:
#                     sections = self.privacy_categories[category].get("dpdpa_sections", [])
#                     dpdpa_mapping["relevant_sections"].extend(sections)

#         # Remove duplicates and sort
#         dpdpa_mapping["relevant_sections"] = sorted(list(set(dpdpa_mapping["relevant_sections"])))

#         # Add compliance requirements based on sections
#         for section in dpdpa_mapping["relevant_sections"]:
#             if section == "section_5":
#                 dpdpa_mapping["compliance_requirements"].append("Establish lawful basis for processing")
#             elif section == "section_8":
#                 dpdpa_mapping["compliance_requirements"].append("Implement data fiduciary obligations")

#         return dpdpa_mapping

#     def _calculate_privacy_risk_score(self, privacy_clauses: List[Dict], constitutional_compliance: Dict, dpdpa_mapping: Dict) -> Dict[str, Any]:
#         """Calculate overall privacy risk score"""
#         # Base risk calculation
#         constitutional_score = constitutional_compliance.get("compliance_score", 0)
        
#         # Risk factors
#         high_risk_keywords = ["surveillance", "monitoring", "tracking", "profiling", "automated decision"]
#         risk_mentions = 0
        
#         for clause in privacy_clauses:
#             clause_text = clause["text"].lower()
#             for keyword in high_risk_keywords:
#                 if keyword in clause_text:
#                     risk_mentions += 1
#                     break

#         # Calculate risk score (inverted - higher compliance = lower risk)
#         base_risk = 1.0 - constitutional_score
#         risk_adjustment = min(0.3, risk_mentions * 0.1)
#         overall_risk = min(1.0, base_risk + risk_adjustment)

#         return {
#             "overall_score": round((1.0 - overall_risk) * 100, 2),  # Convert to compliance percentage
#             "risk_level": "high" if overall_risk > 0.7 else "medium" if overall_risk > 0.4 else "low",
#             "constitutional_component": round(constitutional_score * 100, 2),
#             "risk_factors": risk_mentions,
#             "calculation_timestamp": datetime.now().isoformat()
#         }

#     def _trace_constitutional_privacy_pathway(self, categorization: Dict) -> List[Dict[str, Any]]:
#         """Trace constitutional reasoning pathway for privacy analysis"""
#         pathway = []

#         # Step 1: Constitutional source
#         pathway.append({
#             "step": 1,
#             "constitutional_provision": "Article 21",
#             "principle": "Right to Life and Personal Liberty",
#             "reasoning": "Article 21 protects life and personal liberty, which includes the right to privacy as established in Puttaswamy judgment"
#         })

#         # Step 2: Privacy right establishment
#         pathway.append({
#             "step": 2,
#             "constitutional_provision": "Article 21 (interpreted)",
#             "principle": "Right to Privacy as Fundamental Right",
#             "reasoning": "In Puttaswamy v Union of India (2017), the Supreme Court established privacy as an intrinsic part of Article 21",
#             "case_reference": "Justice K.S. Puttaswamy (Retd.) v. Union of India, (2017) 10 SCC 1"
#         })

#         # Step 3: Privacy categorization
#         for category, data in categorization.items():
#             if isinstance(data, dict) and data.get("score", 0) > 0.5:
#                 category_info = self.privacy_categories.get(category, {})
#                 pathway.append({
#                     "step": len(pathway) + 1,
#                     "constitutional_provision": "Article 21 (privacy dimensions)",
#                     "principle": category_info.get("description", category),
#                     "reasoning": f"Document provisions affect {category}, which is protected under Article 21 privacy framework",
#                     "dpdpa_connection": category_info.get("dpdpa_sections", [])
#                 })

#         # Step 4: DPDPA implementation
#         pathway.append({
#             "step": len(pathway) + 1,
#             "constitutional_provision": "DPDPA 2023",
#             "principle": "Statutory Implementation of Privacy Rights",
#             "reasoning": "DPDPA 2023 implements constitutional privacy rights through specific data protection provisions",
#             "implementation_note": "DPDPA provisions must comply with Article 21 privacy standards established in Puttaswamy"
#         })

#         return pathway

#     def _identify_privacy_critical_issues(self, privacy_clauses: List[Dict], test_results: Dict, puttaswamy_analysis: Dict) -> List[str]:
#         """Identify critical privacy issues"""
#         critical_issues = []

#         # Check constitutional test failures
#         for test_name, test_data in test_results.items():
#             if test_data.get("score", 0) < 0.5:
#                 critical_issues.append(f"Failed {test_name} constitutional test")

#         # Check Puttaswamy principle violations
#         for principle_name, principle_data in puttaswamy_analysis.items():
#             if principle_data.get("compliance_score", 0) < 0.4:
#                 critical_issues.append(f"Non-compliance with {principle_name}")
            
#             violations = principle_data.get("violations", [])
#             critical_issues.extend(violations[:2])  # Add top 2 violations

#         return critical_issues[:5]  # Return top 5 critical issues

#     def _generate_privacy_recommendations(self, critical_issues: List[str], test_results: Dict) -> List[str]:
#         """Generate privacy compliance recommendations"""
#         recommendations = []

#         # Address constitutional test failures
#         for test_name, test_data in test_results.items():
#             if test_data.get("score", 0) < 0.6:
#                 if test_name == "legitimate_government_aim":
#                     recommendations.append("Clearly establish legitimate purposes for privacy-affecting provisions")
#                 elif test_name == "necessity":
#                     recommendations.append("Demonstrate necessity of privacy limitations for achieving stated aims")
#                 elif test_name == "proportionality":
#                     recommendations.append("Ensure privacy limitations are proportionate to legitimate aims")

#         # General recommendations
#         if len(critical_issues) > 0:
#             recommendations.extend([
#                 "Conduct comprehensive privacy impact assessment",
#                 "Implement privacy-by-design principles",
#                 "Establish clear consent mechanisms",
#                 "Define data minimization practices",
#                 "Create transparent privacy notices"
#             ])

#         return recommendations[:7]  # Return top 7 recommendations

#     def _get_relevant_privacy_precedents(self) -> List[Dict[str, str]]:
#         """Get relevant privacy legal precedents"""
#         return [
#             {
#                 "case_name": "Justice K.S. Puttaswamy (Retd.) v. Union of India",
#                 "year": "2017",
#                 "significance": "Established privacy as fundamental right under Article 21",
#                 "relevance": "Constitutional foundation for privacy rights"
#             },
#             {
#                 "case_name": "Kharak Singh v. State of U.P.",
#                 "year": "1963",
#                 "significance": "Early recognition of privacy dimensions",
#                 "relevance": "Historical development of privacy jurisprudence"
#             },
#             {
#                 "case_name": "District Registrar and Collector v. Canara Bank",
#                 "year": "2005",
#                 "significance": "Privacy in information disclosure",
#                 "relevance": "Informational privacy protection"
#             }
#         ]

#     def _assess_article_21_compliance(self, constitutional_compliance: Dict) -> str:
#         """Assess overall Article 21 compliance status"""
#         compliance_score = constitutional_compliance.get("compliance_score", 0)
        
#         if compliance_score >= 0.8:
#             return "high_compliance"
#         elif compliance_score >= 0.6:
#             return "moderate_compliance"
#         elif compliance_score >= 0.4:
#             return "low_compliance"
#         else:
#             return "non_compliance"

#     def _generate_privacy_error_response(self, error_message: str) -> Dict[str, Any]:
#         """Generate error response for failed privacy analysis"""
#         return {
#             "error": True,
#             "error_message": error_message,
#             "privacy_clauses": [],
#             "constitutional_compliance": {"article_21_compliance": "error"},
#             "privacy_risk_score": {"overall_score": 0, "error": True},
#             "analysis_timestamp": datetime.now().isoformat()
#         }


"""
Article 21 Privacy Rights Specialized Analyzer - ENHANCED VERSION WITH CONFIDENCE SCORING
Enhanced with comprehensive privacy analysis framework and semantic confidence calculation
"""

import logging
import re
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime

try:
    from core.knowledge_graph.neo4j_manager import ConstitutionalKnowledgeGraph
except ImportError:
    ConstitutionalKnowledgeGraph = None

logger = logging.getLogger(__name__)


class Article21PrivacyAnalyzer:
    """Specialized analyzer for Article 21 privacy rights implications with enhanced confidence scoring"""

    def __init__(self):
        try:
            if ConstitutionalKnowledgeGraph:
                self.kg = ConstitutionalKnowledgeGraph()
            else:
                self.kg = None
        except Exception as e:
            logger.warning(f"Knowledge graph not available: {str(e)}")
            self.kg = None

        self.privacy_keywords = self._initialize_privacy_keywords()
        self.privacy_categories = self._initialize_privacy_categories()
        self.puttaswamy_principles = self._initialize_puttaswamy_principles()
        self.dpdpa_mapping = self._initialize_dpdpa_mapping()

    def _initialize_privacy_keywords(self) -> Dict[str, List[str]]:
        """Initialize privacy-related keywords for detection - ENHANCED VERSION"""
        return {
            "personal_data": [
                "personal information", "private data", "sensitive data",
                "personal details", "identity", "personal records",
                "biographical data", "personal identifiers"
            ],
            "bodily_privacy": [
                "bodily integrity", "physical examination", "medical examination",
                "blood test", "dna", "genetic", "body cavity search",
                "surveillance", "monitoring", "tracking", "biometric"
            ],
            "communications_privacy": [
                "telephone", "email", "correspondence", "wiretap",
                "intercepted", "communication", "message", "conversation",
                "privacy of communication", "secrecy of mail"
            ],
            "informational_privacy": [
                "confidentiality", "disclosure", "publication", "reputation",
                "defamation", "privacy of information", "secrecy",
                "anonymity", "confidential information"
            ],
            "legal_remedies": [
                "writ", "petition", "habeas corpus", "mandamus", "quo warranto",
                "certiorari", "prohibition", "declaration", "injunction",
                "article 32", "article 226", "enforcement"
            ],
            "dpdpa_2023_terms": [
                "data fiduciary", "data processor", "consent manager",
                "sensitive personal data", "lawful basis", "data principal",
                "data breach", "anonymization", "pseudonymization",
                "data retention", "right to erasure", "right to correction"
            ],
            "article_21_terms": [
                "fundamental right", "intrinsic part", "dignified existence",
                "autonomy", "informational privacy", "bodily integrity",
                "liberty", "personal liberty", "puttaswamy"
            ],
            "constitutional_framework": [
                "constitution", "fundamental rights", "article 14", "article 19",
                "article 21", "article 32", "basic structure", "rule of law",
                "constitutional validity", "reasonable restriction"
            ]
        }

    def _initialize_privacy_categories(self) -> Dict[str, Dict]:
        """Initialize privacy categories with evaluation criteria"""
        return {
            "informational_privacy": {
                "definition": "Right to control personal information",
                "weight": 0.25,
                "score": 0
            },
            "bodily_privacy": {
                "definition": "Right to bodily integrity and autonomy",
                "weight": 0.25,
                "score": 0
            },
            "communications_privacy": {
                "definition": "Right to privacy of communications",
                "weight": 0.25,
                "score": 0
            },
            "territorial_privacy": {
                "definition": "Right to privacy of space",
                "weight": 0.25,
                "score": 0
            }
        }

    def _initialize_puttaswamy_principles(self) -> Dict[str, Dict]:
        """Initialize key principles from Justice Puttaswamy judgment"""
        return {
            "autonomy": {
                "description": "Individual autonomy and self-determination",
                "cases": ["Puttaswamy v. UoI (2017)"],
                "relevance_score": 0
            },
            "dignity": {
                "description": "Human dignity as intrinsic to privacy",
                "cases": ["Puttaswamy v. UoI (2017)", "NALSA v. UoI (2014)"],
                "relevance_score": 0
            },
            "informational_self_determination": {
                "description": "Right to control personal information",
                "cases": ["Puttaswamy v. UoI (2017)"],
                "relevance_score": 0
            },
            "non_disclosure": {
                "description": "Right not to disclose personal information",
                "cases": ["Puttaswamy v. UoI (2017)"],
                "relevance_score": 0
            }
        }

    def _initialize_dpdpa_mapping(self) -> Dict[str, Dict]:
        """Map privacy categories to DPDPA 2023 sections"""
        return {
            "informational_privacy": ["Section 4", "Section 8", "Section 18"],
            "bodily_privacy": ["Section 4", "Section 18"],
            "communications_privacy": ["Section 4", "Section 8"],
            "territorial_privacy": ["Section 4"]
        }

    def _calculate_classification_confidence(self, 
                                            privacy_clauses: List[Dict],
                                            privacy_categorization: Dict,
                                            document_text: str) -> Tuple[float, str]:
        """
        Calculate confidence score for privacy classification - ENHANCED VERSION
        Returns: (confidence_score: float, confidence_level: str)
        """
        
        try:
            # Factor 1: Clause count (higher = more confident) [Max 30%]
            clause_count = len(privacy_clauses) if privacy_clauses else 0
            clause_confidence = min(1.0, (clause_count / 10)) * 30
            
            # Factor 2: Category diversity [Max 20%]
            categories_found = sum(1 for cat, data in privacy_categorization.items()
                                  if isinstance(data, dict) and data.get("score", 0) > 0.5)
            category_confidence = min(1.0, (categories_found / 4)) * 20
            
            # Factor 3: Keyword density across all categories [Max 25%]
            total_keywords_found = 0
            for clause in privacy_clauses:
                if isinstance(clause, dict) and "privacy_keywords" in clause:
                    total_keywords_found += len(clause.get("privacy_keywords", []))
            
            keyword_confidence = min(1.0, (total_keywords_found / 20)) * 25
            
            # Factor 4: Constitutional references [Max 15%]
            constitutional_keywords = ["article", "constitution", "fundamental", "right", "puttaswamy"]
            constitutional_mentions = sum(1 for keyword in constitutional_keywords
                                         if keyword.lower() in document_text.lower())
            constitutional_confidence = min(1.0, (constitutional_mentions / 5)) * 15
            
            # Factor 5: Document length normalization [Max 10%]
            min_length = 500  # characters
            doc_length = len(document_text)
            if doc_length < min_length:
                length_confidence = (doc_length / min_length) * 10
            else:
                length_confidence = 10
            
            # Calculate final confidence (sum of weighted factors)
            final_confidence = (
                clause_confidence +
                category_confidence +
                keyword_confidence +
                constitutional_confidence +
                length_confidence
            )
            
            # Determine confidence level
            if final_confidence >= 70:
                confidence_level = "High"
            elif final_confidence >= 50:
                confidence_level = "Medium"
            else:
                confidence_level = "Low"
            
            logger.info(f"Confidence Calculation: Clauses={clause_confidence:.1f}% + "
                       f"Categories={category_confidence:.1f}% + "
                       f"Keywords={keyword_confidence:.1f}% + "
                       f"Constitutional={constitutional_confidence:.1f}% + "
                       f"Length={length_confidence:.1f}% = {final_confidence:.1f}%")
            
            return round(final_confidence, 1), confidence_level
            
        except Exception as e:
            logger.error(f"Error calculating confidence: {str(e)}")
            return 50.0, "Medium"

    def _extract_privacy_clauses(self, document_text: str) -> List[Dict]:
        """Extract privacy-related clauses from document text"""
        privacy_clauses = []
        
        # Split into paragraphs/sentences
        paragraphs = document_text.split('\n\n')
        
        for para in paragraphs:
            if len(para.strip()) > 20:
                # Check if paragraph contains privacy keywords
                found_keywords = []
                for category, keywords in self.privacy_keywords.items():
                    for keyword in keywords:
                        if keyword.lower() in para.lower():
                            found_keywords.append(keyword)
                
                if found_keywords:
                    privacy_clauses.append({
                        "text": para[:200] + "..." if len(para) > 200 else para,
                        "privacy_keywords": found_keywords,
                        "category_matches": len(found_keywords),
                        "intensity_score": min(1.0, len(found_keywords) / 5)
                    })
        
        return privacy_clauses

    def _categorize_privacy_implications(self, document_text: str) -> Dict:
        """Categorize privacy implications across four dimensions"""
        categorization = {}
        
        for category, keywords in self.privacy_keywords.items():
            if category in ["informational_privacy", "bodily_privacy", "communications_privacy", "territorial_privacy"]:
                matches = sum(1 for kw in keywords if kw.lower() in document_text.lower())
                score = min(1.0, matches / 5)
                
                categorization[category] = {
                    "score": score,
                    "matches": matches,
                    "keywords_found": [kw for kw in keywords if kw.lower() in document_text.lower()]
                }
        
        return categorization

    def _apply_constitutional_test(self, document_text: str) -> Dict:
        """Apply three-fold constitutional test"""
        return {
            "legitimate_aim": {
                "satisfied": "state" in document_text.lower() and "interest" in document_text.lower(),
                "score": 0.7 if "state" in document_text.lower() else 0.3
            },
            "necessity": {
                "satisfied": "necessary" in document_text.lower() or "required" in document_text.lower(),
                "score": 0.6
            },
            "proportionality": {
                "satisfied": "balance" in document_text.lower() or "proportionate" in document_text.lower(),
                "score": 0.5
            }
        }

    def analyze_privacy_implications(self, 
                                    document_text: str,
                                    document_type: str = "general") -> Dict[str, Any]:
        """
        Comprehensive privacy analysis with ENHANCED CONFIDENCE SCORING
        """
        
        logger.info(f"Starting privacy analysis for {document_type}")
        
        # Extract privacy clauses
        privacy_clauses = self._extract_privacy_clauses(document_text)
        
        # Categorize privacy implications
        privacy_categorization = self._categorize_privacy_implications(document_text)
        
        # Apply constitutional test
        constitutional_test = self._apply_constitutional_test(document_text)
        
        # CALCULATE CONFIDENCE SCORE
        analysis_confidence, confidence_level = self._calculate_classification_confidence(
            privacy_clauses,
            privacy_categorization,
            document_text
        )
        
        # Calculate overall compliance
        total_score = sum(cat.get("score", 0) for cat in privacy_categorization.values()) / len(privacy_categorization) if privacy_categorization else 0
        compliance_score = round(total_score * 100, 1)
        
        return {
            "document_type": document_type,
            "analysis_timestamp": datetime.now().isoformat(),
            
            # CONFIDENCE METRICS - NEW
            "analysis_confidence": analysis_confidence,
            "analysis_confidence_level": confidence_level,
            "classification_confidence": round(analysis_confidence * 0.95, 1),  # Slightly lower
            
            # Privacy Analysis Results
            "privacy_clauses_found": len(privacy_clauses),
            "privacy_clauses": privacy_clauses[:5],  # Top 5 clauses
            
            # Categorization Results
            "privacy_categorization": privacy_categorization,
            
            # Constitutional Test Results
            "constitutional_test_results": constitutional_test,
            "test_satisfaction_score": round(
                sum(test["score"] for test in constitutional_test.values()) / len(constitutional_test) * 100,
                1
            ),
            
            # Overall Compliance
            "overall_privacy_score": compliance_score,
            "risk_level": "low" if compliance_score >= 70 else "medium" if compliance_score >= 50 else "high",
            
            # Puttaswamy Principles Mapping
            "puttaswamy_principles": self.puttaswamy_principles,
            
            # DPDPA Mapping
            "dpdpa_relevant_sections": {
                cat: sections for cat, sections in self._initialize_dpdpa_mapping().items()
                if privacy_categorization.get(cat, {}).get("score", 0) > 0.3
            },
            
            # Recommendations
            "recommendations": self._generate_recommendations(
                compliance_score,
                privacy_clauses,
                privacy_categorization,
                analysis_confidence
            ),
            
            "analysis_status": "completed"
        }

    def _generate_recommendations(self,
                                 compliance_score: float,
                                 privacy_clauses: List[Dict],
                                 categorization: Dict,
                                 confidence: float) -> List[str]:
        """Generate recommendations based on analysis results"""
        recommendations = []
        
        if confidence < 60:
            recommendations.append("âš ï¸ Low confidence score - Manual review recommended for detailed assessment")
        
        if compliance_score < 70:
            recommendations.append("ðŸ”´ Privacy compliance below 70% - Enhanced privacy safeguards recommended")
        
        if len(privacy_clauses) < 3:
            recommendations.append("ðŸ“‹ Limited privacy clauses found - Consider comprehensive privacy framework review")
        
        if categorization.get("informational_privacy", {}).get("score", 0) < 0.5:
            recommendations.append("ðŸ” Strengthen informational privacy protections")
        
        if categorization.get("bodily_privacy", {}).get("score", 0) < 0.5:
            recommendations.append("ðŸ’ª Enhance bodily integrity protections")
        
        if not recommendations:
            recommendations.append("âœ… Privacy framework satisfactory - Maintain current safeguards")
        
        return recommendations

    def get_analysis_summary(self, analysis_results: Dict) -> str:
        """Generate human-readable summary of privacy analysis"""
        summary = f"""
ðŸ“Š PRIVACY ANALYSIS SUMMARY
{'=' * 50}

Document Type: {analysis_results.get('document_type', 'Unknown')}

ðŸŽ¯ CONFIDENCE METRICS:
   Analysis Confidence: {analysis_results.get('analysis_confidence', 0)}% ({analysis_results.get('analysis_confidence_level', 'Unknown')})
   Classification Confidence: {analysis_results.get('classification_confidence', 0)}%

ðŸ“ˆ PRIVACY ASSESSMENT:
   Overall Privacy Score: {analysis_results.get('overall_privacy_score', 0)}%
   Privacy Clauses Found: {analysis_results.get('privacy_clauses_found', 0)}
   Risk Level: {analysis_results.get('risk_level', 'Unknown')}

ðŸ›ï¸ CONSTITUTIONAL COMPLIANCE:
   Test Satisfaction Score: {analysis_results.get('test_satisfaction_score', 0)}%

ðŸ’¡ RECOMMENDATIONS:
   {chr(10).join('   â€¢ ' + rec for rec in analysis_results.get('recommendations', []))}
"""
        return summary
